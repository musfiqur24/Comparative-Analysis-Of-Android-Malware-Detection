{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN0Hbep1Bl5W+kiz/wWKhpV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_O3iWCKddFoO","executionInfo":{"status":"ok","timestamp":1721113530238,"user_tz":-480,"elapsed":90304,"user":{"displayName":"Musfiqur Rahman","userId":"10444599639774013556"}},"outputId":"de1d756d-687a-45b0-cdb1-879bd2f9ebbb"},"outputs":[{"output_type":"stream","name":"stdout","text":["RFE Results:\n","{'Decision Tree': {'Accuracy': 0.8164893617021277, 'Precision': 0.8673643411359048, 'Recall': 0.7636642781633605, 'F1 Score': 0.7807819844769159}, 'SVM': {'Accuracy': 0.8184840425531915, 'Precision': 0.8771179600331438, 'Recall': 0.7639282089506758, 'F1 Score': 0.7816106871365869}}\n","\n","Tree-Based Results:\n","{'Decision Tree': {'Accuracy': 0.9235372340425532, 'Precision': 0.9201416179854841, 'Recall': 0.9172344928942613, 'F1 Score': 0.9186397943415707}, 'SVM': {'Accuracy': 0.9235372340425532, 'Precision': 0.9202737079299244, 'Recall': 0.9170661959979092, 'F1 Score': 0.9186115016780261}}\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_selection import RFE\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.impute import SimpleImputer\n","\n","# Load dataset with dtype specification to handle mixed types\n","df = pd.read_csv('Original_Dataset.csv', dtype=str)\n","\n","# Replace '?' with NaN\n","df.replace('?', np.nan, inplace=True)\n","\n","# Convert target variable 'class' to numerical values\n","df['class'] = df['class'].map({'S': 0, 'B': 1})\n","\n","# Convert all columns to numeric, forcing errors to NaN\n","df = df.apply(pd.to_numeric, errors='coerce')\n","\n","# Separate features (X) and target variable (y)\n","X = df.drop(columns=['class'])\n","y = df['class']\n","\n","# Remove rows where y is NaN\n","non_nan_indices = ~y.isna()\n","X = X[non_nan_indices]\n","y = y[non_nan_indices]\n","\n","# Impute missing values in features\n","imputer = SimpleImputer(strategy='mean')\n","X = imputer.fit_transform(X)\n","\n","# Ensure y is not empty\n","if len(y) == 0:\n","    raise ValueError(\"Target variable y is empty after preprocessing.\")\n","\n","# Recursive Feature Elimination (RFE)\n","logreg = LogisticRegression(max_iter=10000)\n","rfe_selector = RFE(logreg, n_features_to_select=10)\n","X_rfe = rfe_selector.fit_transform(X, y)\n","\n","# Feature Importance from Decision Tree\n","rf = RandomForestClassifier()\n","rf.fit(X, y)\n","importances = rf.feature_importances_\n","indices = np.argsort(importances)[-10:]\n","X_tree = X[:, indices]\n","\n","# List of selected features\n","selected_features = {\n","    'RFE': np.array(df.columns[:-1])[rfe_selector.get_support()].tolist(),\n","    'Tree-Based': np.array(df.columns[:-1])[indices].tolist()\n","}\n","\n","# Save selected features to CSV files\n","pd.DataFrame(selected_features['RFE']).to_csv('selected_features_rfe.csv', index=False, header=['Feature'])\n","pd.DataFrame(selected_features['Tree-Based']).to_csv('selected_features_tree.csv', index=False, header=['Feature'])\n","\n","# Function to train and evaluate models\n","def evaluate_model(X, y):\n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Initialize models\n","    dt_model = DecisionTreeClassifier()\n","    svm_model = SVC()\n","\n","    # Train the models\n","    dt_model.fit(X_train, y_train)\n","    svm_model.fit(X_train, y_train)\n","\n","    # Make predictions\n","    dt_pred = dt_model.predict(X_test)\n","    svm_pred = svm_model.predict(X_test)\n","\n","    # Calculate metrics\n","    results = {\n","        'Decision Tree': {\n","            'Accuracy': accuracy_score(y_test, dt_pred),\n","            'Precision': precision_score(y_test, dt_pred, average='macro'),\n","            'Recall': recall_score(y_test, dt_pred, average='macro'),\n","            'F1 Score': f1_score(y_test, dt_pred, average='macro')\n","        },\n","        'SVM': {\n","            'Accuracy': accuracy_score(y_test, svm_pred),\n","            'Precision': precision_score(y_test, svm_pred, average='macro'),\n","            'Recall': recall_score(y_test, svm_pred, average='macro'),\n","            'F1 Score': f1_score(y_test, svm_pred, average='macro')\n","        }\n","    }\n","    return results\n","\n","# Evaluate models on each feature selection method\n","results_rfe = evaluate_model(X_rfe, y)\n","results_tree = evaluate_model(X_tree, y)\n","\n","# Print results\n","print(\"RFE Results:\")\n","print(results_rfe)\n","print(\"\\nTree-Based Results:\")\n","print(results_tree)\n"]}]}